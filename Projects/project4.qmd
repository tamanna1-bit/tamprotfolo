---
title: "Client Report - Can you Predict that?"
subtitle: "Course DS 250"
author: "Tamanna Sangroula"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
    
---

```{python}
#| label: libraries
#| include: false
import pandas as pd
import numpy as np
import plotly.express as px
from sklearn.model_selection import train_test_split
```


## Elevator pitch

_For this project, I have created charts to evalutate potential relationship between the home variable and befor1980. I used 'livearea', 'numbdrm', 'sprice' as the variables to compare the results. i also build a classification model labeling houses as being built “before 1980” or “during or after 1980”. At last, it also justifies the classification model by discussing the most important features selected by my model. _

```{python}


# Include and execute your code here
df = pd.read_csv("https://raw.githubusercontent.com/byuidatascience/data4dwellings/master/data-raw/dwellings_ml/dwellings_ml.csv")

```

__Highlight the Questions and Tasks__

## QUESTION|TASK 1

__Create 2-3 charts that evaluate potential relationships between the home variables and before1980. Explain what you learn from the charts that could help a machine learning algorithm.__

_The following charts evaluate th epotential relationships between the home variables and before1980. I used 'livearea', 'numbdrm', and 'sprice' home variables. In the first chart, I used the 'livearea' which is the toal livable area in house. The homes built befor 1980 has more livable area accourding to my data selection. The second chart was the chart to evaluate the distribution of bedrooms for homes built before and after 1980. It looks like building built after 1980 has lesser bedrooms than building built before 1980. The final chart is evalutating the selling price for homes built before nad after 198. The results shows that the house build before 1980 is selling in lower price than the house built after 1980. The charts can help us identify the important features and understand the model better which is insightful to a machine learning algorithms. It can help perform predicitive tasks._

```{python}
#| label: Q1
#| code-summary: Read and format data
# Include and execute your code here
# Chart 1: Scatter plot - Area vs. Before1980

data = pd.DataFrame({
    'livearea': [1752, 1130, 1268, 1502, 1348],
    'numbdrm': [4, 2, 2, 4, 3  ],
    'sprice': [158000, 339000, 269850, 885000, 105000],
    'before1980': ["Yes","No", "Yes", "No", "Yes"]
})

chart1 = px.histogram(data, x='livearea', nbins= 25,color='before1980', 
                  labels={'livearea': 'liveable area', 'before1980': 'Built Before 1980'},
                  title='Relationship between liveable Area and Before 1980')
chart1.show()

# Chart 2: Box plot - Bedrooms vs. Before1980
chart2 = px.bar(data, x='before1980', y='numbdrm', color='before1980', 
              labels={'numbdrm': 'Number of Bedrooms', 'before1980': 'Built Before 1980'},
              title='Distribution of Bedrooms for Homes Built Before and After 1980')
chart2.show()

chart3 = px.box(data, x='before1980', y='sprice', color='before1980', 
              labels={'sprice': 'selling price', 'before1980': 'Built Before 1980'},
              title='Selling Price for Homes Built Before and After 1980')
chart3.show()

```


## QUESTION|TASK 2

__Build a classification model labeling houses as being built “before 1980” or “during or after 1980”. Your goal is to reach or exceed 90% accuracy. Explain your final model choice (algorithm, tuning parameters, etc) and describe what other models you tried.__

_I chose RandomForestClassifier to build a classification model labeling houses as being built "before 1980" or "during or after 1980". It showed the accuracy of more than 90%. It was choosen as it a versatile classifier that include robustness, interpretability, scalablilty across various types of datasets. I also tried using DecisionTrees classifier, but I found RandomForests more comfortable._

Accuracy: 93.74%

```{python}
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

columns_to_drop = ["parcel", "deduct", "netprice", "tasp", "smonth", "syear"]
new_data = df.drop(columns=columns_to_drop, errors="ignore")

# Define features and target variable
data_features = new_data.drop(columns=["before1980", "yrbuilt"]).columns
features = data_features.tolist()

X = new_data[features]
y = new_data["before1980"]

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Define the classifier
classifier = RandomForestClassifier(
    bootstrap=True,
    criterion="entropy",
    max_features="sqrt",
    n_estimators=300,
    n_jobs=-1,
    random_state=42,
)

# Train the classifier
classifier.fit(X_train, y_train)

# Make predictions
pred = classifier.predict(X_test)

# Calculate the accuracy of the model
accuracy = accuracy_score(y_test, pred)

# Display accuracy in a table
accuracy_df = pd.DataFrame({"Metric": ["Accuracy"], "Value": [accuracy]})
print(accuracy_df)

```


## QUESTION|TASK 3

__Justify your classification model by discussing the most important features selected by your model. This discussion should include a chart and a description of the features.__

_The followinf chart shows the feature importance provided by the model. According the top 8 most important feature imprtance, 'livearea' is a variable which is of the most importance in my model. Followed by 'sprice' which is the selling price. As per the Chart, 'quality_C' is the least importance features out of the top 8 import features._

```{python}

# Retrieve feature importances from the trained model
feature_importances = classifier.feature_importances_

# Create a DataFrame to store feature names and importances
feature_importance_df = pd.DataFrame({"Feature": features, "Importance": feature_importances})

# Sort the DataFrame by feature importance
feature_importance_df = feature_importance_df.sort_values(by="Importance", ascending=False)

top_n = 8
top_features = feature_importance_df.head(top_n)

fig = px.bar(
    top_features,
    x="Importance",
    y="Feature", 
    title="Top 8 Most Important Features",
    labels={"Importance": "Feature Importance", "Feature": "Feature"},
    hover_name="Feature",
    hover_data={"Feature": False, "Importance": True},  # Show Importance in hover tooltip
)

# Show the chart
fig.show()


```


## QUESTION|TASK 4

__Describe the quality of your classification model using 2-3 different evaluation metrics. You also need to explain how to interpret each of the evaluation metrics you use.__

_I have tried to see the quality of the classification model by using the 3 most common evaluation metrics - Accuracy, which we did in the question 2, Precision and Recall. Accuracuy is the metric which shows the proportion of corretly classified instances our of the total instances. Percision is the matric that shows the proportion of true positive predictions among all positive prediction.And Recall us the the merrice that shows the proportion of ture positive predictions among all actual positive instances in the dataset._
  
```{python}
#| label: Q4
#| code-summary: Read and format data

from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
# Calculate the accuracy of the model
accuracy = accuracy_score(y_test, pred)

# Calculate the precision of the model
precision = precision_score(y_test, pred)


# Calculate the recall of the model
recall = recall_score(y_test, pred)

# Display accuracy, precision, and recall in a table
evaluation_df = pd.DataFrame({"Metric": ["Accuracy", "Precision", "Recall"], "Value": [accuracy, precision, recall]})
print(evaluation_df)

```
