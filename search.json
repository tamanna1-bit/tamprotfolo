[
  {
    "objectID": "exploration.html",
    "href": "exploration.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "exploration.html#title-2-header",
    "href": "exploration.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 1\nProject 2\nProject 3\nProject 4\nProject 5",
    "crumbs": [
      "DS250 Projects"
    ]
  },
  {
    "objectID": "projects.html#repo-for-all-my-projects",
    "href": "projects.html#repo-for-all-my-projects",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 1\nProject 2\nProject 3\nProject 4\nProject 5",
    "crumbs": [
      "DS250 Projects"
    ]
  },
  {
    "objectID": "Projects/project3.html",
    "href": "Projects/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Uncomment the entire section to use this template\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project5.html",
    "href": "Projects/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Uncomment the entire section to use this template\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project4.html",
    "href": "Projects/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Uncomment the entire section to use this template\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "cleansing.html",
    "href": "cleansing.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "cleansing.html#title-2-header",
    "href": "cleansing.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html#title-2-header",
    "href": "index.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "competition.html",
    "href": "competition.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "competition.html#title-2-header",
    "href": "competition.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "ml.html#title-2-header",
    "href": "ml.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "Physicist, Mathematician, Cambridge professor.\n\nisaac@applesdofall.org | My wikipedia page\n\n\n\nStanding on the shoulders of giants\n\n\nLaws of motion, gravitation, minting coins, disliking Robert Hooke\n\n\n\nCooling, power series, optics, alchemy, planetary motions, apples.\n\n\n\n\n1654-1660 The King’s School, Grantham.\nJune 1661 - now Trinity College, Cambridge\n\nSizar\n\n1667 - death Trinity College, Cambridge\n\nFellow\n\n\n\n\n2012 President, Royal Society, London, UK\nAssociate, French Academy of Science, Paris, France\n\n\n\n\n\n\n1669 Newton Sir I, De analysi per æquationes numero terminorum infinitas.\n1669 Lectiones opticæ.\netc. etc. etc.\n\n\n\n2012 Infinitesimal calculus for solutions to physics problems, SMBC patent 001\n\n\n\n\n1600 Royal Mint, London\n\nWarden\nMinted coins\n\n1600 Lucasian professor of Mathematics, Cambridge University"
  },
  {
    "objectID": "resume.html#currently",
    "href": "resume.html#currently",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "Standing on the shoulders of giants\n\n\nLaws of motion, gravitation, minting coins, disliking Robert Hooke\n\n\n\nCooling, power series, optics, alchemy, planetary motions, apples."
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "1654-1660 The King’s School, Grantham.\nJune 1661 - now Trinity College, Cambridge\n\nSizar\n\n1667 - death Trinity College, Cambridge\n\nFellow"
  },
  {
    "objectID": "resume.html#awards",
    "href": "resume.html#awards",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "2012 President, Royal Society, London, UK\nAssociate, French Academy of Science, Paris, France"
  },
  {
    "objectID": "resume.html#publications",
    "href": "resume.html#publications",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "1669 Newton Sir I, De analysi per æquationes numero terminorum infinitas.\n1669 Lectiones opticæ.\netc. etc. etc.\n\n\n\n2012 Infinitesimal calculus for solutions to physics problems, SMBC patent 001"
  },
  {
    "objectID": "resume.html#occupation",
    "href": "resume.html#occupation",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "1600 Royal Mint, London\n\nWarden\nMinted coins\n\n1600 Lucasian professor of Mathematics, Cambridge University"
  },
  {
    "objectID": "Projects/project1.html",
    "href": "Projects/project1.html",
    "title": "Project 1 - Trends with the Name.",
    "section": "",
    "text": "From this project, I have visualized and analyzed the uses of names in diffrent year. I have compared the use of diffrent names with the year and tried to see how the trends are with the name. I have used plotly express to plot charts and used different tools with in plotly express such as shape, annotations.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#elevator-pitch",
    "href": "Projects/project1.html#elevator-pitch",
    "title": "Project 1 - Trends with the Name.",
    "section": "",
    "text": "From this project, I have visualized and analyzed the uses of names in diffrent year. I have compared the use of diffrent names with the year and tried to see how the trends are with the name. I have used plotly express to plot charts and used different tools with in plotly express such as shape, annotations.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-1",
    "href": "Projects/project1.html#questiontask-1",
    "title": "Project 1 - Trends with the Name.",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nHow does your name at your birth year compare to its use historically?\nMy name, Tamanna, is not in the data so, I use a name with the same meaning as mine, Desire. As I visualized the data, the name ‘Desire’ is used quite a good number of times. During my birt year, that name was used for total of 64 times. It dropped from 88 times to 64 times. But historically its use statred to grow form the year 1985 and started to drop from year 2010. \n\n\nRead and format data\n# Include and execute your code here\n# target = 'Tamanna'\n# count = df[df['name']== target].shape[0]\n# print(count)\nmy_data = df[df['name']== 'Desire']\nscatterplot = px.scatter(my_data,x='year',y = 'Total', title = \"Scatterplot of use of name 'Desire'\")\n#scatterplot.show()\n\nmy_year = 2003  \nscatterplot.add_shape(\n    dict(\n        type='line',\n        x0=my_year,\n        x1=my_year,\n        y0=0,\n        y1=len(my_data)*3,\n        line=dict(color='green'),\n        name='My Birth Year'\n    )\n)\nscatterplot.add_annotation(\n    x=my_year,\n    y=len(my_data)*3,\n    text = '2003',\n    showarrow = True\n)\nscatterplot.show()",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-2",
    "href": "Projects/project1.html#questiontask-2",
    "title": "Project 1 - Trends with the Name.",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nIf you talked to someone named Brittany on the phone, what is your guess of his or her age? What ages would you not guess?\nI think Brittany would be in her mid 30s to early 40s. As the name reached the hightest in 1990 with the total use of 32.562k times. There is lesser chance of her being younger than 34 years old as the uses of that name statred to drop. \n\n\nRead and format data\n# Include and execute your code here\nbrittany_data = df[df['name']== 'Brittany']\nboxplot = px.line(brittany_data, x='year', y=\"Total\", title = 'LineGraph for Brittany')\n\nboxplot.show()",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-3",
    "href": "Projects/project1.html#questiontask-3",
    "title": "Project 1 - Trends with the Name.",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nMary, Martha, Peter, and Paul are all Christian names. From 1920 - 2000, compare the name usage of each of the four names. What trends do you notice?\nAs we compare the names; Mary, Martha, Peter, and Paul, we can find which was used the most or the least. From year 1920 to year 2000, ‘Mary’ was used the most where as ‘Peter was least used until 1953 after which ’Marth’ was least used. The use of all these name dropped after late 1960s. But the most dropped name was ‘Mary’. Now, the uses of all these names are in similiar number, being used less than 10k. \n\n\nRead and format data\n# Include and execute your code here\nnames = df.query(\"name in ['Mary', 'Martha', 'Peter', 'Paul'] and year &gt;= 1920 and year &lt;=2000\")\nchristian_names = px.line(names, x='year', y='Total', color='name', title='Christian Names used (1920 - 2000)')\nchristian_names.show()",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-4",
    "href": "Projects/project1.html#questiontask-4",
    "title": "Project 1 - Trends with the Name.",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nThink of a unique name from a famous movie. Plot the usage of that name and see how changes line up with the movie release. Does it look like the movie had an effect on usage?\nI have tried using a bar graph to visualize the use of the name ‘Austin’. I took the name from the movie “Austin Powers” which was released in 1997. It was a hughly popular movie. Seing the trend with the name, the use of name ‘Asutin’ was at its peak. Follwing the year, the name rose a little but then it statred to drop. In my opinion, the movie’s popularity did not gave a huge impact to the use of the name. \n\n\nRead and format data\n# Include and execute your code here\naustin_data = df[df['name']== 'Austin']\naustin_chart  = px.bar(austin_data,x='year',y = 'Total', title = \"Bar Graph of use of name 'Austin'\")\n#scatterplot.show()\n\naustin_year = 1997  \naustin_chart.add_shape(\n    dict(\n        type='line',\n        x0=austin_year,\n        x1=austin_year,\n        y0=0,\n        y1=len(austin_data)*215,\n        line=dict(color='red'),\n        name='Use of Austin name'\n    )\n)\naustin_chart.add_annotation(\n    x=austin_year,\n    y=len(austin_data)*200,\n    text = 'Austin Powers release year 1997',\n    showarrow = True\n)\naustin_chart.show()",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project2.html",
    "href": "Projects/project2.html",
    "title": "Project 2 - Late flights and missing data (JSON files)",
    "section": "",
    "text": "This project shows the analysis of delays on flights of 7 airports over the course of 10 years. I have cleaned the data as well as searched for insights about flight delays. Based on my analysis Salt lakt City Airport has the least delays of an average of 0.12 hrs. It seems like September and November are the best months to travel as it has the least average delays. Weather is one of the biggest factors for delay in flights. Other reasons for delay were Air Carrier, National Aviation System, Late-Arriving Aircraft, and Security.\n\n\nRead and format project data\n# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\ndf = pd.read_json(\"https://raw.githubusercontent.com/byuidatascience/data4missing/master/data-raw/flights_missing/flights_missing.json\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#elevator-pitch",
    "href": "Projects/project2.html#elevator-pitch",
    "title": "Project 2 - Late flights and missing data (JSON files)",
    "section": "",
    "text": "This project shows the analysis of delays on flights of 7 airports over the course of 10 years. I have cleaned the data as well as searched for insights about flight delays. Based on my analysis Salt lakt City Airport has the least delays of an average of 0.12 hrs. It seems like September and November are the best months to travel as it has the least average delays. Weather is one of the biggest factors for delay in flights. Other reasons for delay were Air Carrier, National Aviation System, Late-Arriving Aircraft, and Security.\n\n\nRead and format project data\n# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\ndf = pd.read_json(\"https://raw.githubusercontent.com/byuidatascience/data4missing/master/data-raw/flights_missing/flights_missing.json\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-1",
    "href": "Projects/project2.html#questiontask-1",
    "title": "Project 2 - Late flights and missing data (JSON files)",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nFix all of the varied missing data types in the data to be consistent (all missing values should be displayed as “NaN”). In your report include one record example (one row) from your new data, in the raw JSON format. Your example should display the “NaN” for at least one missing value.\nFixed and replaced all the missing values in the data with “NaN”. \n\n\nRead and format data\n# Include and execute your code here\n# Assuming df is your DataFrame\ncolumns_missing_values = df.columns[df.isnull().any()].tolist()\nfor each in columns_missing_values:\n    df[each].fillna(\"NaN\", inplace=True) \nsearch_value = \"NaN\"\n\nrows_with_search_value = df[(df == search_value).any(axis=1)]\nfor index, row in rows_with_search_value.iterrows():\n  if index != 2:\n    print(row)\n    break\n\n\nairport_code                                                                 IAD\nairport_name                     Washington, DC: Washington Dulles International\nmonth                                                                    Febuary\nyear                                                                      2005.0\nnum_of_flights_total                                                       10042\nnum_of_delays_carrier                                                        284\nnum_of_delays_late_aircraft                                                  631\nnum_of_delays_nas                                                            691\nnum_of_delays_security                                                         4\nnum_of_delays_weather                                                         28\nnum_of_delays_total                                                         1639\nminutes_delayed_carrier                                                  15573.0\nminutes_delayed_late_aircraft                                              39840\nminutes_delayed_nas                                                          NaN\nminutes_delayed_security                                                     169\nminutes_delayed_weather                                                     1359\nminutes_delayed_total                                                      78878\nName: 9, dtype: object\n\n\ninclude figures chunks and discuss your findings in the figure.",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-2",
    "href": "Projects/project2.html#questiontask-2",
    "title": "Project 2 - Late flights and missing data (JSON files)",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nWhich airport has the worst delays? Discuss the metric you chose, and why you chose it to determine the “worst” airport. Your answer should include a summary table that lists (for each airport) the total number of flights, total number of delayed flights, proportion of delayed flights, and average delay time in hours.\nTaking the metrics, proportiona of delayed flights and average delay time, SFO airport has the worst delay with 26.10% delay rate by an average delay of 0.27hrs. It is followed by ORD airport being very colse to SFO with an average dealy of 0.26 hrs. As ORD has the highest average and the highest proportion delays in flights, it is the “worst: airport in terms fof delay.\n\n\nRead and format data\n# Include and execute your code here\n#df.query(\"num_of_flights_total &gt; 50\") \n# Include and execute your code here\n\ngroup = df.groupby('airport_code').agg({\n    'num_of_flights_total': 'sum',\n    'num_of_delays_total': 'sum',\n    'minutes_delayed_total': 'sum'\n})\n\n# Create a new DataFrame with calculated metrics\nnew_data = (group.assign(\n              flights_total=lambda row: row['num_of_flights_total'],\n              delays_total=lambda row: row['num_of_delays_total'],\n              minutes_delayed_total=lambda row: row['minutes_delayed_total'],\n              proportion_delayed=lambda row: (row['num_of_delays_total'] / row['num_of_flights_total']),\n              avg_delay_time_hrs=lambda row: row['minutes_delayed_total'] / (60 * row['num_of_flights_total'])\n          )\n          .sort_values('num_of_flights_total', ascending=False)\n)\nnew_data['proportion_delayed'] = new_data['proportion_delayed'].apply(lambda x: '{:.2%}'.format(x))\nnew_data['avg_delay_time_hrs'] = new_data['avg_delay_time_hrs'].apply(lambda x: '{:.2f} hrs'.format(x))\n\n\nmydat = new_data.head(10)\\\n    .tail(10)\\\n    .filter([\"airport_code\",\"flights_total\",\"delays_total\",\"proportion_delayed\", \"avg_delay_time_hrs\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\n\nflights_total\ndelays_total\nproportion_delayed\navg_delay_time_hrs\n\n\nairport_code\n\n\n\n\n\n\n\n\nATL\n4430047\n902443\n20.37%\n0.20 hrs\n\n\nORD\n3597588\n830825\n23.09%\n0.26 hrs\n\n\nDEN\n2513974\n468519\n18.64%\n0.17 hrs\n\n\nSFO\n1630945\n425604\n26.10%\n0.27 hrs\n\n\nSLC\n1403384\n205160\n14.62%\n0.12 hrs\n\n\nSAN\n917862\n175132\n19.08%\n0.15 hrs\n\n\nIAD\n851571\n168467\n19.78%\n0.20 hrs",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-3",
    "href": "Projects/project2.html#questiontask-3",
    "title": "Project 2 - Late flights and missing data (JSON files)",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nWhat is the best month to fly if you want to avoid delays of any length? Discuss the metric you chose and why you chose it to calculate your answer. Include one chart to help support your answer, with the x-axis ordered by month. (To answer this question, you will need to remove any rows that are missing the Month variable.)\nAccording to the bar graph below, September is the best month to fly if you want followed by November. As these months have the lowest delay rate i.e. 0.16452 and 0.16683 respectively. As per the analysis, it is best to avoid flying in Decmber and June as these months have the fighest delays in flights.\ninclude figures in chunks and discuss your findings in the figure.\n\n\nShow the code\ndf = df.dropna(subset=['month'])\n\ndf['month'] = df['month'].replace('Febuary', 'February')\n\nmonth_data = df.groupby('month').agg({\n    'num_of_flights_total': 'sum',\n    'num_of_delays_total': 'sum'\n}).reset_index()\n\n\nmonth_data['proportion_delayed'] = month_data['num_of_delays_total'] / month_data['num_of_flights_total']\n\nmonth_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n\nchart = px.bar(month_data, \n               x='month', \n               y='proportion_delayed',\n               color='proportion_delayed',  # Color bars based on the proportion_delayed values\n               color_continuous_scale='viridis',  # Set color scale\n               title='Proportion of Delayed Flights by Month',\n               labels={'proportion_delayed': 'Proportion Delayed'},\n               category_orders={'month': month_order},\n               width=800,  # Set the width of the chart\n               height=500,  # Set the height of the chart\n               template='plotly_dark',  # Use a dark template for better visibility\n               )\n\nchart.update_layout(\n    xaxis_title='Month',\n    yaxis_title='Proportion Delayed',\n    showlegend=False,  # Hide the legend to avoid clutter\n)\n# chart = px.bar(month_data, x='month', y='proportion_delayed', \n#                title='Proportion of Delayed Flights by Month',\n#                labels={'proportion_delayed': 'Proportion Delayed'},\n#                category_orders={'month': month_order})\n\nchart.show()",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-4",
    "href": "Projects/project2.html#questiontask-4",
    "title": "Project 2 - Late flights and missing data (JSON files)",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nAccording to the BTS website, the “Weather” category only accounts for severe weather delays. Mild weather delays are not counted in the “Weather” category, but are actually included in both the “NAS” and “Late-Arriving Aircraft” categories. Your job is to create a new column that calculates the total number of flights delayed by weather (both severe and mild). You will need to replace all the missing values in the Late Aircraft variable with the mean. Show your work by printing the first 5 rows of data in a table. Use these three rules for your calculations:\n100% of delayed flights in the Weather category are due to weather\n30% of all delayed flights in the Late-Arriving category are due to weather.\nFrom April to August, 40% of delayed flights in the NAS category are due to weather. The rest of the months, the proportion rises to 65%\nThis shows the columns that calculates the total number of flights delayed by weather. There are two conditions where the flights gets delayed - sever and mild. NAS and Late-Arriving Aircraft includes mild weather delays as well. ATL has the highest number of dealays in total beacuse of severe weather. In the late arriavl Aircraft category, ORD has the highest number of delays because of mild weather. It is the same case forthe NAS category as well, ORD airport has the highest dealys with 3519.75 flights delay because of mild weather.\n\n\nRead and format data\n# Include and execute your code here\n\n# Replace missing values in 'num_of_delays_late_aircraft' with the mean\ndf['num_of_delays_late_aircraft'] = df['num_of_delays_late_aircraft'].replace(-999, df['num_of_delays_late_aircraft'][df['num_of_delays_late_aircraft'] != -999].mean())\n\n# Define weights for mild delays\nweights = {'late_arrive': 0.3, 'NAS_cat': 0.4, 'other': 0.65}\n\n# Create columns with weighted delays\ndf['weather_Severe'] = df['num_of_delays_weather']\ndf['late_arrive_mild'] = df['num_of_delays_late_aircraft'] * weights['late_arrive']\ndf['NAS_cat_mild'] = df['num_of_delays_nas'] * np.where(df['month'].isin(['April', 'May', 'June', 'July', 'August']), weights['NAS_cat'], weights['other'])\n\n# Calculate the total weather-related delays\ndf['Total'] = df[['weather_Severe', 'late_arrive_mild', 'NAS_cat_mild']].sum(axis=1).round(2)\nprint(df[['airport_code','weather_Severe', 'late_arrive_mild', 'NAS_cat_mild', 'Total']].head(5))\n\n\n  airport_code  weather_Severe  late_arrive_mild  NAS_cat_mild    Total\n0          ATL             448        332.731222       2988.70  3769.43\n1          DEN             233        278.400000        607.75  1119.15\n2          IAD              61        317.400000        581.75   960.15\n3          ORD             306        676.500000       3519.75  4502.25\n4          SAN              56        204.000000        414.70   674.70",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-5",
    "href": "Projects/project2.html#questiontask-5",
    "title": "Project 2 - Late flights and missing data (JSON files)",
    "section": "QUESTION|TASK 5",
    "text": "QUESTION|TASK 5\nUsing the new weather variable calculated above, create a barplot showing the proportion of all flights that are delayed by weather at each airport. Discuss what you learn from this graph\n_The Bar graph shows the porportion of all flights that are delayed by weather at each airport. Overall ATL airport is has the highest rate with more than 0.007 porportion dealyed by weather. Whereas SAN airport has the lowest dealy rate becuase of weather being ony 0.0047 porportion.\n\n\nShow the code\n# Calculate the total number of flights and delayed flights by weather for each airport\nairport_stats = df.groupby('airport_code').agg({\n    'weather_Severe': 'sum',  # Total delayed flights by weather\n    'num_of_flights_total': 'sum'  # Total number of flights\n}).reset_index()\n\n# Calculate the proportion of delayed flights by weather\nairport_stats['proportion_delayed_weather'] = airport_stats['weather_Severe'] / airport_stats['num_of_flights_total']\n\n# Create a more visually appealing bar chart using Plotly Express\nchart = px.bar(airport_stats, \n               x='airport_code', \n               y='proportion_delayed_weather',\n               color='proportion_delayed_weather',  # Color bars based on the proportion_delayed_weather values\n               color_continuous_scale='viridis',  # Set color scale\n               title='Proportion of all Flights Delayed by Weather at Each Airport',\n               labels={'proportion_delayed_weather': 'Proportion Delayed by Weather'},\n               width=800, \n               height=500, \n               template='plotly_dark',\n               )\n\nchart.update_layout(\n    xaxis_title='Airport Code',\n    yaxis_title='Proportion Delayed by Weather',\n    showlegend=False,  # Hide the legend to avoid clutter\n)\n\nchart.show()",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "full_stack.html",
    "href": "full_stack.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "full_stack.html#title-2-header",
    "href": "full_stack.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "story_telling.html",
    "href": "story_telling.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "story_telling.html#title-2-header",
    "href": "story_telling.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  }
]